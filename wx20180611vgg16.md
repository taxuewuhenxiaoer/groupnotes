VGG16

1、卷积（略）

2、池化   转载https://blog.csdn.net/app_12062011/article/details/57075538仅此用于learning.

池化操作一般跟在卷积后面，池化窗口的大小一般就是步长；

（1）常见池化操作分别是平均池化 mean pooling 和最大池化 max pooling;

​       平均池化：通过计算图像区域的平均值作为该地区池化后的值；

​      最大池化：图像区域中最大值作为池化后的值；

​      随机池化：只需对图像中元素按照概率的大小随机选择，即元素值大的被选中的概率也大；

（2）重叠池化 overlapping pooling

​       相邻池化窗口有重叠区域 sizeX>stride;

参考论文：  Krizhevsky, I. Sutskever, andG. Hinton, “Imagenet classification with deep convolutional neural networks,”in NIPS,2012.

（3）空金字塔池化 spatial Pyramid pooling

空间金字塔池化可以把任何尺度的图像的卷积特征转换成相同维度，不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义。

一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs6z9n3fd8j20h706g758.jpg"/>

空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs6zh56v0yj20lb0dzq4b.jpg"/>

对于不同的图像要得到相同大小的pooling结果，就需要根据图像的大小动态的计算池化窗口的大小和步长。假设conv5输出的大小为 a * a，需要得到  n* n大小的池化结果，可以让窗口大小sizeX为 <img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs6zrh7br7j201x00wa9t.jpg"/>，步长为<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs6zs3imwwj201u00za9t.jpg"/>。

SPP其实就是一种多个scale的pooling，可以获取图像中的多尺度信息；在CNN中加入SPP后，可以让CNN处理任意大小的输入，这让模型变得更加的flexible。

参考文献：Kaiming  He, Xiangyu Zhang, Shaoqing Ren, Jian Su,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,LSVRC-2014 contest

3、步长  转载 https://blog.csdn.net/errors_in_life/article/details/65950699仅此用于学习

卷积核移动的步长（stride）小于卷积核的边长（一般为正方行）时，变会出现卷积核与原始输入矩阵作用范围在区域上的重叠（overlap），卷积核移动的步长（stride）与卷积核的边长相一致时，不会出现重叠现象。

4、卷积核（略）

5、Padding（略）

6、通道（略）

7、VGG16

VGG16分为16层；

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs704leinuj20du0c07dq.jpg"/>

看懂一些式子表达：

**Conv3-512   →    第三层卷积后维度变成512；**

**Conv3_2 s=2     →     第三层卷积层里面的第二子层，滑动步长等于2（每次移动两个格子）；**

**步骤:【1、从INPUT到Conv1：】**

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs70bbv0ccj20fk0baq2y.jpg"/>

首先两个黄色的是卷积层，是VGG16网络结构十六层当中的第一层（Conv1_1）和第二层（Conv1_2），他们合称为Conv1。

我们主要讲述第一个，也就是第一层（Conv1_1），它怎么把一个300* 300* 3的矩阵变成一个300 * 300* 64的矩阵？

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs70chu885j209b09faa8.jpg"/>

我们假设蓝色框是一个RGB图像，橙色是一个3* 3* 3的卷积核，我们对一个三维的27个数求和，然后扫过去，按照第一部分算的得出来的是一维的298*298的矩阵（因为卷积核也是三维所以结果是一维）；

然后回想一下什么是Padding、前面也讲过它的概念了；所以补了0，回到了300* 300* 1；

然后，VGG16这一层安置有64个卷积核，那么，原来的300* 300* 1变成300* 300* 64

于是我们的到了想要的东西；最后的绿色框；

**【2、从Conv1到Conv2之间的过度：】**

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs70jwmomdj20800bcq2x.jpg"/>





**【3、顺利来到Conv2并且结构完全一样进入Conv3：】**

我们知道原来INPUT是300* 300* 3过了第一层出来时150* 150* 64

那么第二层仍然有池化有128个卷积核，联想推理：

出来的应该是75* 75* 128；这一步没有问题，我们继续往下分析：

**【4、进入Conv3的推演：】**

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs70o6fnb8j20iy0co74h.jpg"/>

可以知道第三层有256个卷积核，包含三层小的卷基层；

**【5、从Conv3到Conv4之间的过度：】**

<img src="http://ww1.sinaimg.cn/large/9f6c4109ly1fs71r4cac3j207r0axglm.jpg"/>

后面的方法很简单，根据我给的那个VGG16的表格查找每一层里面有什么卷积核？多少个？池化的大小？步长多少？是否需要Padding？解决这些问题，你的VGG16就已经完全可以从头到尾说清楚了！！！































